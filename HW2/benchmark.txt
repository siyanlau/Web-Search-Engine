$ time python -m engine.parser
Loaded 30000 docs
Doc lengths saved to data\doc_lengths.pkl
real    0m4.352s
user    0m0.061s
sys     0m0.061s


$ time python -m engine.indexer
Loaded 30000 docs
Doc lengths saved to data\doc_lengths.pkl
Inverted index saved to data\intermediate_index.pkl
Indexer: index saved to data\intermediate_index.pkl
Inverted index loaded from data\intermediate_index.pkl
Indexer: index loaded from data\intermediate_index.pkl
Sample postings for 'communication': [(0, 1), (425, 2), (681, 1), (686, 1), (2262, 1)]

real    0m6.485s
user    0m0.076s
sys     0m0.046s



$ time python -m engine.searcher
Lexicon loaded: 67130 terms from data/index.lexicon
Doc lengths loaded from data/doc_lengths.pkl
=== Boolean mode sample ===
Lexicon loaded: 67130 terms from data/index.lexicon
Doc lengths loaded from data/doc_lengths.pkl
AND: [(29997, 19.91968378092275)]
OR : [(244, 9.914205225791427), (2332, 13.847476522972126), (16190, 9.460681382319317), (26147, 9.305469102752186), (26150, 9.38243337270348)]

=== BM25 sample (top 10) ===
29997 19.92

real    0m0.344s
user    0m0.061s
sys     0m0.108s





$ time python -m bench_search
Lexicon loaded: 67130 terms from data/index.lexicon
Lexicon loaded: 67130 terms from data/index.lexicon
Doc lengths loaded from data/doc_lengths.pkl
Mode=BM25  Queries=200  avg=0.03ms  p50=0.02ms  p95=0.04ms  max=1.37ms

real    0m0.358s
user    0m0.061s
sys     0m0.062s




$ python -m engine.searcher
Lexicon loaded: 67130 terms from data/index.lexicon
Doc lengths loaded from data/doc_lengths.pkl
Lexicon loaded: 67130 terms from data/index.lexicon
Doc lengths loaded from data/doc_lengths.pkl
=== Boolean vs DAAT (set equality & timing) ===
Lexicon loaded: 67130 terms from data/index.lexicon
Lexicon loaded: 67130 terms from data/index.lexicon

Q: overturned carriage
  AND equal: True | sizes: base=1 daat=1 | time base=0.0016s daat=0.3191s
  OR  equal: True  | sizes: base=6 daat=6   | time base=0.0012s daat=0.2361s
Lexicon loaded: 67130 terms from data/index.lexicon
Lexicon loaded: 67130 terms from data/index.lexicon

Q: communication policy
  AND equal: True | sizes: base=0 daat=0 | time base=0.0004s daat=0.3274s
  OR  equal: True  | sizes: base=221 daat=221   | time base=0.0010s daat=0.2459s
Lexicon loaded: 67130 terms from data/index.lexicon
Lexicon loaded: 67130 terms from data/index.lexicon

Q: machine learning
  AND equal: True | sizes: base=0 daat=0 | time base=0.0002s daat=0.4023s
  OR  equal: True  | sizes: base=188 daat=188   | time base=0.0009s daat=0.2580s
Lexicon loaded: 67130 terms from data/index.lexicon
Lexicon loaded: 67130 terms from data/index.lexicon

Q: u.s policy
  AND equal: True | sizes: base=7 daat=7 | time base=0.0028s daat=0.2918s
  OR  equal: True  | sizes: base=824 daat=824   | time base=0.0020s daat=0.3563s
Lexicon loaded: 67130 terms from data/index.lexicon
Lexicon loaded: 67130 terms from data/index.lexicon

Q: 3.14 math
  AND equal: True | sizes: base=27 daat=27 | time base=0.0006s daat=0.2070s
  OR  equal: True  | sizes: base=27 daat=27   | time base=0.0004s daat=0.3017s

=== BM25 sample (top 10) ===
2 19.44
7 15.259
8 15.21
3 14.556
1 13.687
5 13.092
6 13.092
9 12.979
4 12.141
0 11.948





$ time python -m engine.parser
Loaded 1000000 docs
Doc lengths saved to data/doc_lengths.pkl

real    1m43.765s
user    0m0.016s
sys     0m0.124s






$ time python -m engine.indexer
[Indexer] Building index from data\marco_medium.tsv
Loaded 1000000 docs
Doc lengths saved to data/doc_lengths.pkl
ListWriter: wrote 0 bytes to data/index.postings
Lexicon saved: 686254 terms to data/index.lexicon
[Indexer] Wrote postings → data/index.postings
[Indexer] Wrote lexicon  → data/index.lexicon
Sample postings for 'munteanu': 1 docs

real    2m17.967s
user    0m0.077s
sys     0m0.123s






$ time python -m engine.build_runs_mp --input data/marco_medium.tsv --outdir data/runs --batch-size 100000 --workers 4
[BuildRunsMP] Doc lengths saved to data/doc_lengths.pkl  N=1000000
[BuildRunsMP] Total docs=1000000  total rows=39397529  runs=10

real    1m7.835s
user    0m0.091s
sys     0m0.108s



$ time python -m engine.build_runs_mp --input data/marco_medium.tsv --outdir data/runs --batch-size 50000 --workers 4
Doc lengths saved to data/doc_lengths.pkl
[BuildRunsMP] Doc lengths saved to data/doc_lengths.pkl  N=1000000
[BuildRunsMP] Total docs=1000000  total rows=39397529  runs=20

real    1m3.639s
user    0m0.093s
sys     0m0.137s




$ time python -m engine.merger data/runs/run_*.tsv
ListWriter: wrote 322881336 bytes to data/index.postings
Lexicon saved: 686254 terms to data/index.lexicon
[Merger] Wrote postings -> data/index.postings
[Merger] Wrote lexicon  -> data/index.lexicon

real    1m59.295s
user    0m0.061s
sys     0m0.185s





[with 1M docs]
$ time python -m engine.searcher
Lexicon loaded: 686254 terms from data/index.lexicon
Lexicon loaded: 686254 terms from data/index.lexicon
Doc lengths loaded from data/doc_lengths.pkl
Lexicon loaded: 686254 terms from data/index.lexicon
Doc lengths loaded from data/doc_lengths.pkl
=== Boolean vs DAAT (set equality & timing) ===

Q: overturned carriage
  AND equal: True | sizes: base=1 daat=1 | time base=0.0160s daat=0.0002s
  OR  equal: True  | sizes: base=284 daat=284   | time base=0.0048s daat=0.0001s      

Q: communication policy
  AND equal: True | sizes: base=30 daat=30 | time base=0.0175s daat=0.0025s
  OR  equal: True  | sizes: base=8863 daat=8863   | time base=0.0189s daat=0.0032s    

Q: machine learning
  AND equal: True | sizes: base=49 daat=49 | time base=0.0171s daat=0.0023s
  OR  equal: True  | sizes: base=8275 daat=8275   | time base=0.0184s daat=0.0022s    

Q: u.s policy
  AND equal: True | sizes: base=232 daat=232 | time base=0.0408s daat=0.0059s
  OR  equal: True  | sizes: base=25041 daat=25041   | time base=0.0432s daat=0.0054s  

Q: 3.14 math
  AND equal: True | sizes: base=5 daat=5 | time base=0.0063s daat=0.0002s
  OR  equal: True  | sizes: base=1440 daat=1440   | time base=0.0109s daat=0.0008s    

=== BM25 sample (top 10) ===
2 21.35
137268 17.726
8 16.777
3 15.874
329341 15.759
521492 15.559
749035 15.282
1 15.147
5 14.507

real    0m8.200s
user    0m0.045s
sys     0m0.015s






(after adding varbyte/gap ID compression)
$ time python -m engine.searcher
Lexicon loaded: 686254 terms from data/index.lexicon
Lexicon loaded: 686254 terms from data/index.lexicon
Doc lengths loaded from data/doc_lengths.pkl
Lexicon loaded: 686254 terms from data/index.lexicon
Doc lengths loaded from data/doc_lengths.pkl
=== Boolean vs DAAT (set equality & timing) ===

Q: overturned carriage
  AND equal: True | sizes: base=1 daat=1 | time base=0.0481s daat=0.0002s
  OR  equal: True  | sizes: base=284 daat=284   | time base=0.0455s daat=0.0001s

Q: communication policy
  AND equal: True | sizes: base=30 daat=30 | time base=0.0608s daat=0.0042s
  OR  equal: True  | sizes: base=8863 daat=8863   | time base=0.0556s daat=0.0043s

Q: machine learning
  AND equal: True | sizes: base=49 daat=49 | time base=0.0587s daat=0.0041s
  OR  equal: True  | sizes: base=8275 daat=8275   | time base=0.0587s daat=0.0040s

Q: u.s policy
  AND equal: True | sizes: base=232 daat=232 | time base=0.0846s daat=0.0124s
  OR  equal: True  | sizes: base=25041 daat=25041   | time base=0.0806s daat=0.0108s

Q: 3.14 math
  AND equal: True | sizes: base=5 daat=5 | time base=0.0470s daat=0.0005s
  OR  equal: True  | sizes: base=1440 daat=1440   | time base=0.0476s daat=0.0010s

=== BM25 sample (top 10) ===
134847 21.618
134846 21.377
137371 21.303
442216 19.972
693533 19.046

real    0m10.069s
user    0m0.030s
sys     0m0.030s





$ time python -m engine.build_runs_mp --input data/collection.tsv --outdir data/runs --batch-size 100000 --workers 4
Doc lengths saved to data/doc_lengths.pkl
[BuildRunsMP] Doc lengths saved to data/doc_lengths.pkl  N=8841823
[BuildRunsMP] Total docs=8841823  total rows=351891634  runs=89

real    10m32.799s
user    0m0.218s
sys     0m0.170s



(My CPU has 8 cores. Now it's maxed out. CPU utilization is pretty good in this run.)
$ time python -m engine.build_runs_mp --input data/collection.tsv --outdir data/runs --batch-size 100000 --workers 8
Doc lengths saved to data/doc_lengths.pkl
[BuildRunsMP] Doc lengths saved to data/doc_lengths.pkl  N=8841823
[BuildRunsMP] Total docs=8841823  total rows=351891634  runs=89

real    4m32.633s
user    0m0.123s
sys     0m0.108s








Trying to figure out why merger was so slow!!
$ python -c "import pstats; p=pstats.Stats('merger.pstats'); p.strip_dirs().sort_stats('tottime').print_stats(30)"
Wed Oct 15 16:57:40 2025    merger.pstats

         1361750748 function calls (1361750684 primitive calls) in 569.119 seconds

   Ordered by: internal time
   List reduced from 242 to 30 due to restriction <30>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1  126.758  126.758  569.111  569.111 merger.py:103(merge)
111544307  110.278    0.000  160.583    0.000 runio.py:71(__next__)
  1256139   79.485    0.000  177.182    0.000 listio.py:25(add_term)
111544219   36.958    0.000   36.958    0.000 {built-in method _heapq.heappop}
111544218   35.232    0.000   35.232    0.000 {built-in method _heapq.heappush}
111544307   30.347    0.000  190.930    0.000 {built-in method builtins.next}
223072014   26.745    0.000   26.745    0.000 {method 'write' of '_io.BufferedWriter' objects}
223072015   21.089    0.000   21.089    0.000 {built-in method _struct.pack}
111544307   20.344    0.000   21.005    0.000 {method 'readline' of '_io.TextIOWrapper' objects}
  1256139   19.926    0.000   29.280    0.000 {built-in method builtins.sorted}
111544307   16.704    0.000   16.704    0.000 {method 'split' of 'str' objects}
111544767   12.596    0.000   12.596    0.000 {method 'rstrip' of 'str' objects}
111544218    9.354    0.000    9.354    0.000 listio.py:36(<lambda>)
  2084661    8.809    0.000    8.809    0.000 listio.py:46(<listcomp>)
  2084661    8.178    0.000    8.178    0.000 listio.py:47(<listcomp>)
  3340800    2.573    0.000    2.573    0.000 {method 'tell' of '_io.BufferedWriter' objects}
  1256138    1.042    0.000    1.042    0.000 {method 'clear' of 'dict' objects}
  1256138    1.000    0.000    1.000    0.000 lexicon.py:47(add)
6681988/6681986    0.612    0.000    0.612    0.000 {built-in method builtins.len}
   229860    0.335    0.000    0.335    0.000 {built-in method _codecs.utf_8_decode}
   229860    0.261    0.000    0.596    0.000 <frozen codecs>:319(decode)
  2084964    0.249    0.000    0.249    0.000 {method 'append' of 'list' objects}
  1256142    0.162    0.000    0.162    0.000 {method 'items' of 'dict' objects}
   229860    0.065    0.000    0.065    0.000 <frozen codecs>:331(getstate)
       90    0.009    0.000    0.009    0.000 {built-in method io.open}
       55    0.001    0.000    0.001    0.000 {built-in method nt.stat}
       11    0.001    0.000    0.001    0.000 {built-in method marshal.loads}
       11    0.001    0.000    0.001    0.000 {built-in method io.open_code}
      146    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:96(_path_join)
       11    0.000    0.000    0.000    0.000 {method 'read' of '_io.BufferedReader' objects}